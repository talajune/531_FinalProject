{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fairlearn\n",
        "!pip install xgboost\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCN5lOqECmcl",
        "outputId": "aa7604c8-b899-4a2e-ba1c-491ac055cda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.10.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.1/234.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
            "Installing collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.10.0\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=f214d3dbfedf2a00dbf9407427514e7308da53408b922483aaf74474231a9734\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OPTvPPs89Qi"
      },
      "outputs": [],
      "source": [
        "# loading in one-hot encoded, cleaned (floats), stratified subsample of x_train, y_train, y_test, y_train for implementing bias mitigation techniqes.\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import json\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from itertools import islice, combinations\n",
        "import itertools\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, cohen_kappa_score, f1_score, recall_score, precision_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fairlearn.metrics import equalized_odds_difference, equalized_odds_ratio, demographic_parity_ratio\n",
        "from fairlearn.metrics import demographic_parity_difference\n",
        "from pyspark import SparkContext, SparkConf\n",
        "if __name__ == '__main__':\n",
        "  start_time = time.time()\n",
        "  conf = SparkConf().setAppName('531_final_proj').setMaster('local[*]')\n",
        "  sc = SparkContext.getOrCreate(conf=conf)\n",
        "  sc.setSystemProperty('spark.driver.memory', '4g')\n",
        "  sc.setSystemProperty('spark.executor.memory', '4g')\n",
        "  sc.setLogLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "X_test = pd.read_csv('/content/X_test.csv', header=None, dtype=float)\n",
        "X_train = pd.read_csv('/content/X_train.csv', header=None, dtype=float)\n",
        "y_test = pd.read_csv('/content/y_test.csv', header=None, dtype=float)\n",
        "y_train = pd.read_csv('/content/y_train.csv', header=None, dtype=float)"
      ],
      "metadata": {
        "id": "vV6JJwcr9_YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train_rdd.take(1)\n",
        "lines = sc.textFile('/content/X_train.csv')\n",
        "rdd = lines.map(lambda row: row.split(','))"
      ],
      "metadata": {
        "id": "cSwgenyWJ5q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make them into rdds now for later\n",
        "X_test_rdd = sc.parallelize(X_test.values.tolist())\n",
        "X_train_rdd = sc.parallelize(X_train.values.tolist())\n",
        "y_test_rdd = sc.parallelize(y_test.values.tolist())\n",
        "y_train_rdd = sc.parallelize(y_train.values.tolist())"
      ],
      "metadata": {
        "id": "ScKgDxFYTWcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_rdd.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "BzYYpwWQRqVT",
        "outputId": "52635a02-1b87-402e-8b4d-1997d76fb86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-6e660e92e235>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   2508\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2510\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2511\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 1) Normal -- Without any bias mitigation or Smote"
      ],
      "metadata": {
        "id": "y5whrc0iB5GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'binary:hinge',\n",
        "    'eval_metric': 'rmse',\n",
        "}\n",
        "xgb_model = xgb.XGBRegressor(**params)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "\n",
        "print(\"XGBoost Model RMSE : \", np.sqrt(mean_squared_error(y_test, preds)))\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(\"XGBoost Model Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9TSjFoELSPe",
        "outputId": "7dae91f9-8690-46e4-d763-8717e8e7fd07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model RMSE :  0.3246700446057128\n",
            "XGBoost Model Accuracy: 0.8945893621357245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stat Parity\n",
        "\n",
        "\n",
        "gender_and_preds = X_test_rdd.map(lambda x: (x[5], x[6]))\n",
        "gender_positive_rates = gender_and_preds.groupByKey().mapValues(lambda preds: sum(preds) / len(preds))\n",
        "\n",
        "\n",
        "gender_positive_rates_collected = gender_positive_rates.collect()\n",
        "\n",
        "#statistical parity difference\n",
        "statistical_parity_difference = abs(gender_positive_rates_collected[0][1] - gender_positive_rates_collected[1][1])\n",
        "\n",
        "print(\"Statistical Parity Difference (Gender):\", statistical_parity_difference)\n",
        "sens_data = X_test_rdd.map(lambda x: (x[5], x[6]))\n",
        "\n",
        "\n",
        "# Collect the results\n",
        "sens_data_collected = sens_data.collect()\n",
        "scalar_sens_data = [gender[0] for gender in sens_data_collected]\n",
        "\n",
        "print(equalized_odds_difference(y_test,\n",
        "                                preds,\n",
        "                                sensitive_features=scalar_sens_data))\n",
        "\n",
        "print(equalized_odds_ratio(y_test,\n",
        "                           preds,\n",
        "                           sensitive_features=scalar_sens_data))\n",
        "# Stat parity gender\n",
        "\n",
        "sens_data = X_test_rdd.map(lambda x: (x[5], x[6]))  # Assuming gender is at index 4 and 5 in each data point\n",
        "\n",
        "# Collect the results\n",
        "sens_data_collected = sens_data.collect()\n",
        "scalar_sens_data = [gender[0] for gender in sens_data_collected]\n",
        "\n",
        "print(\"Statistical Parity Ratio (Gender): \", demographic_parity_ratio(y_test, preds, sensitive_features=scalar_sens_data))\n",
        "\n",
        "\n",
        "# Stat Parity -> medicare vs medicaid (insurance status)\n",
        "\n",
        "sens_data = X_test_rdd.map(lambda x: (x[53:58]))  # Assuming gender is at index 4 and 5 in each data point\n",
        "\n",
        "sens_data_collected = sens_data.collect()\n",
        "\n",
        "scalar_sens_data = [status[0] for status in sens_data_collected]\n",
        "\n",
        "print(\"Equalized Odds Ratio (Insurance Status)\",(equalized_odds_ratio(y_test,\n",
        "                           preds,\n",
        "                           sensitive_features=scalar_sens_data)))\n",
        "\n",
        "print(\"Statistical Parity Ratio (Insurance Status)\", (demographic_parity_ratio(y_test, preds, sensitive_features=scalar_sens_data)))\n",
        "\n",
        "# RACE: Stat Parity & equzlied odds -> race (11-17)\n",
        "sens_data = X_test_rdd.map(lambda x: (x[11:18]))  # Assuming gender is at index 4 and 5 in each data point\n",
        "\n",
        "# Collect the results\n",
        "sens_data_collected = sens_data.collect()\n",
        "scalar_sens_data = [race[0] for race in sens_data_collected]\n",
        "\n",
        "\n",
        "print(\"Equalized Odds Ratio (Race):\",(equalized_odds_ratio(y_test,\n",
        "                           preds,\n",
        "                           sensitive_features=scalar_sens_data)))\n",
        "\n",
        "print(\"Statistical Parity Ratio (Race):\", (demographic_parity_ratio(y_test, preds, sensitive_features=scalar_sens_data)))\n",
        "\n",
        "# AGE\n",
        "sens_data = X_test_rdd.map(lambda x: x[4])  # Assuming gender is at index 4 and 5 in each data point\n",
        "\n",
        "# Collect the results\n",
        "scalar_sens_data = sens_data.collect()\n",
        "#scalar_sens_data = [age[0] for age in sens_data_collected]\n",
        "\n",
        "\n",
        "print(\"Equalized Odds Ratio (Age):\",(equalized_odds_ratio(y_test,\n",
        "                           preds,\n",
        "                           sensitive_features=scalar_sens_data)))\n",
        "\n",
        "print(\"Statistical Parity Ratio (Age):\", (demographic_parity_ratio(y_test, preds, sensitive_features=scalar_sens_data)))\n",
        "\n",
        "\n",
        "#print(\"stat parity difference age:\", (demographic_parity_difference(y_test, preds, sensitive_features=scalar_sens_data)))\n"
      ],
      "metadata": {
        "id": "sBGJO5vuBcRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results with SMOTE\n"
      ],
      "metadata": {
        "id": "vWHKgIWCBegT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sampling imbalance class with smote, smoteen\n",
        "from imblearn.combine import SMOTEENN\n",
        "import collections\n",
        "counter = collections.Counter(y_train)\n",
        "print('Before', counter)\n",
        "# oversampling the train dataset using SMOTE + ENN\n",
        "smenn = SMOTEENN()\n",
        "X_train_smenn, y_train_smenn = smenn.fit_resample (X_train, y_train)\n",
        "counter = collections.Counter (y_train_smenn)\n",
        "print('After', counter)"
      ],
      "metadata": {
        "id": "IVAkXUaXEkxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=3, n_jobs=-1, learning_rate=0.5, random_state=42)\n",
        "xgb_model.fit(X_train_smenn, y_train_smenn)\n",
        "\n",
        "\n",
        "preds = xgb_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test,preds)\n",
        "kappa = cohen_kappa_score(y_test,preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "\n",
        "\n",
        "print(\"Results With Oversampling Smote + ENN\")\n",
        "print(\"XGBoost Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)"
      ],
      "metadata": {
        "id": "ZGHVzFjUEmP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SMOTE RESULTS:/n\")\n",
        "\n",
        "######  GENDER ######\n",
        "# Equalized Odds\n",
        "gender_and_preds = X_test_rdd.map(lambda x: (x[5], x[6]))\n",
        "gender_positive_rates = gender_and_preds.groupByKey().mapValues(lambda preds: sum(preds) / len(preds))\n",
        "gender_positive_rates_collected = gender_positive_rates.collect()\n",
        "statistical_parity_difference = abs(gender_positive_rates_collected[0][1] - gender_positive_rates_collected[1][1])\n",
        "\n",
        "print(\"Statistical Parity Difference (Gender):\", statistical_parity_difference)\n",
        "sens_data = X_test_rdd.map(lambda x: (x[5], x[6]))\n",
        "\n",
        "\n",
        "sens_data_collected = sens_data.collect()\n",
        "scalar_sens_data = [gender[0] for gender in sens_data_collected]\n",
        "\n",
        "print(equalized_odds_difference(y_test,\n",
        "                                preds,\n",
        "                                sensitive_features=scalar_sens_data))\n",
        "\n",
        "print(equalized_odds_ratio(y_test,\n",
        "                           preds,\n",
        "                           sensitive_features=scalar_sens_data))\n",
        "# Stat parity gender with fairness learn metrics\n",
        "\n",
        "sens_data = X_test_rdd.map(lambda x: (x[5], x[6]))\n",
        "sens_data_collected = sens_data.collect()\n",
        "scalar_sens_data = [gender[0] for gender in sens_data_collected]\n",
        "\n",
        "print(\"Statistical Parity Ratio (Gender): \", demographic_parity_ratio(y_test, preds, sensitive_features=scalar_sens_data))\n",
        "\n",
        "\n",
        "# Stat Parity -> medicare vs medicaid (insurance status)\n",
        "\n",
        "sens_data = X_test_rdd.map(lambda x: (x[53:58]))  # gender at index 4,5\n",
        "\n",
        "sens_data_collected = sens_data.collect()\n",
        "\n",
        "scalar_sens_data = [status[0] for status in sens_data_collected]\n",
        "\n",
        "print(\"Equalized Odds Ratio (Insurance Status)\",(equalized_odds_ratio(y_test,\n",
        "                           preds,\n",
        "                           sensitive_features=scalar_sens_data)))\n",
        "\n",
        "print(\"Statistical Parity Ratio (Insurance Status)\", (demographic_parity_ratio(y_test, preds, sensitive_features=scalar_sens_data)))\n",
        "\n",
        "# RACE: Stat Parity & equzlied odds -> race (11-17)\n",
        "sens_data = X_test_rdd.map(lambda x: (x[11:18]))  # Gender index 4, 5\n",
        "\n",
        "# Collect the results\n",
        "sens_data_collected = sens_data.collect()\n",
        "scalar_sens_data = [race[0] for race in sens_data_collected]\n",
        "\n",
        "\n",
        "print(\"Equalized Odds Ratio (Race):\",(equalized_odds_ratio(y_test,\n",
        "                           preds,\n",
        "                           sensitive_features=scalar_sens_data)))\n",
        "\n",
        "print(\"Statistical Parity Ratio (Race):\", (demographic_parity_ratio(y_test, preds, sensitive_features=scalar_sens_data)))\n",
        "\n",
        "# AGE\n",
        "sens_data = X_test_rdd.map(lambda x: x[4])\n",
        "\n",
        "\n",
        "scalar_sens_data = sens_data.collect()\n",
        "#scalar_sens_data = [age[0] for age in sens_data_collected]\n",
        "\n",
        "\n",
        "print(\"Equalized Odds Ratio (Age):\",(equalized_odds_ratio(y_test,\n",
        "                           preds,\n",
        "                           sensitive_features=scalar_sens_data)))\n",
        "\n",
        "print(\"Statistical Parity Ratio (Age):\", (demographic_parity_ratio(y_test, preds, sensitive_features=scalar_sens_data)))\n"
      ],
      "metadata": {
        "id": "reP2tY0qJG9G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}