# Final Project DSCI 531: Unveiling Bias in Patient Triage Systems

## Shreya Raj & Tala Tayebi 

This project investigates biases within a healthcare triage dataset and emphasizes fair treatment across diverse patient groups. Our analysis focuses on sensitive attributes such as race, gender, and insurance status to identify potential inequities. Utilizing data distribution analysis, exploratory data analysis and machine learning models, we assess discrepancies indicative of bias. We develop a baseline predictive model and apply fairness measures like statistical parity and equalized odds, evaluating the impact of sensitive features on outcome predictions. Our methodology includes a comprehensive overview of the "Hospital Triage and Patient History Data" dataset from the Yale New Haven Health System. We prepare our data for our predictive model through stratified sampling and data preprocessing. Applying XGBoost and fairness metrics from fairlearn.metrics, we uncover disparities across race and insurance status, indicating biases in the initial dataset and predictive model. We then discuss the results of data augmentation via oversampling with SMOTE, which targeted disparities in the sensitive attributes identified in our exploratory data analysis and baseline model to help mitigate bias.

Overall, this project highlights the importance of fairness in machine learning applications in healthcare. Our findings on biases across race and insurance status highlight the need for systemic improvements in triage practices and healthcare policies moving forward.

#### Data was too large to upload to Github, please access here: https://drive.google.com/drive/folders/1ZdhtaxIAJmL7Q6wg2dX0ID8V5QfbyCzC?usp=sharing
